train:
  optimizer: Adam
  loss: CrossEntropyLoss
  batch_size: 64
  num_workers: 4
  epochs: 1000
  lr:
    initial: 1.0e-4
    scheduler: TransformerLR
  saving_interval_epochs: 10
  log_interval_steps: 10
  max_saving_checkpoints: 10
eval:
  loss: CrossEntropyLoss
  batch_size: 1    # can only be 1
  num_workers: 4

model: Transformer
device: cuda
random_seed: 3407
checkpoint_dir: './res/weights/'